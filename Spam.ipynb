{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSbvog2mHig_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a0a66a-2f3b-4edc-a2b6-c79201509b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=b6a7efec00c3780867b271fb01b9d9bece2ed42292ebedcaee7fb34426b56e6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from operator import index\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "!pip install langdetect\n",
        "import langdetect as detect\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Download necessary data for natural language processing tasks\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvPyTqOSfqNm",
        "outputId": "1ed40888-2c5c-42b9-f68e-6c4a970ca4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in spam data from CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/spam.csv',\n",
        "                 sep=',', header=0, on_bad_lines='skip', encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "hDVN3lwAf5Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "asI1dCEt65Vx",
        "outputId": "740a4244-1242-4381-8852-fc1aea6756be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   v1                                                 v2  \\\n",
              "0   0  go until jurong point crazy available only in ...   \n",
              "1   0                           ok lar joking wif u oni    \n",
              "2   1  free entry in a wkly comp to win fa cup final ...   \n",
              "3   0       u dun say so early hor u c already then say    \n",
              "4   0  nah i don't think he goes to usf he lives arou...   \n",
              "\n",
              "                                            TokenSMS  \\\n",
              "0  [go, until, jurong, point, crazy, available, o...   \n",
              "1                     [ok, lar, joking, wif, u, oni]   \n",
              "2  [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
              "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
              "4  [nah, i, do, n't, think, he, goes, to, usf, he...   \n",
              "\n",
              "                                        StopTokenSMS  \\\n",
              "0  [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                     [ok, lar, joking, wif, u, oni]   \n",
              "2  [free, entry, wkly, comp, win, fa, cup, final,...   \n",
              "3      [u, dun, say, early, hor, u, c, already, say]   \n",
              "4  [nah, n't, think, goes, usf, lives, around, th...   \n",
              "\n",
              "                                      LengthTokenSMS  \\\n",
              "0  jurong point crazy available bugis great world...   \n",
              "1                                 lar joking wif oni   \n",
              "2  free entry wkly comp win cup final tkts may te...   \n",
              "3                      dun say early hor already say   \n",
              "4         nah n't think goes usf lives around though   \n",
              "\n",
              "                                         LemTokenSMS  \n",
              "0  jurong point crazy available bugis great world...  \n",
              "1                                 lar joking wif oni  \n",
              "2  free entry wkly comp win cup final tkts may te...  \n",
              "3                      dun say early hor already say  \n",
              "4         nah n't think goes usf lives around though  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8525ea65-625b-4a40-a2c5-1da6099680a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>TokenSMS</th>\n",
              "      <th>StopTokenSMS</th>\n",
              "      <th>LengthTokenSMS</th>\n",
              "      <th>LemTokenSMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>jurong point crazy available bugis great world...</td>\n",
              "      <td>jurong point crazy available bugis great world...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>lar joking wif oni</td>\n",
              "      <td>lar joking wif oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
              "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
              "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
              "      <td>free entry wkly comp win cup final tkts may te...</td>\n",
              "      <td>free entry wkly comp win cup final tkts may te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>dun say early hor already say</td>\n",
              "      <td>dun say early hor already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i don't think he goes to usf he lives arou...</td>\n",
              "      <td>[nah, i, do, n't, think, he, goes, to, usf, he...</td>\n",
              "      <td>[nah, n't, think, goes, usf, lives, around, th...</td>\n",
              "      <td>nah n't think goes usf lives around though</td>\n",
              "      <td>nah n't think goes usf lives around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8525ea65-625b-4a40-a2c5-1da6099680a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8525ea65-625b-4a40-a2c5-1da6099680a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8525ea65-625b-4a40-a2c5-1da6099680a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98665edf-391c-45d7-bce0-d89665c3d1df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98665edf-391c-45d7-bce0-d89665c3d1df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98665edf-391c-45d7-bce0-d89665c3d1df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4672,\n  \"fields\": [\n    {\n      \"column\": \"v1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"v2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4668,\n        \"samples\": [\n          \"good no swimsuit allowed \",\n          \"aight i'll text you when i'm back\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TokenSMS\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"StopTokenSMS\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LengthTokenSMS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4607,\n        \"samples\": [\n          \"haha legs neck killing amigos hoping end night burn think could swing like hour\",\n          \"fuuuuck need stop sleepin sup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LemTokenSMS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4607,\n        \"samples\": [\n          \"haha legs neck killing amigos hoping end night burn think could swing like hour\",\n          \"fuuuuck need stop sleepin sup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any \"Unnamed\" columns\n",
        "\n",
        "unnamed_cols = df.columns[df.columns.str.contains(\"Unnamed\")]\n",
        "df.drop(columns=unnamed_cols, inplace=True)"
      ],
      "metadata": {
        "id": "1edcoybQgvy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define regular expression variables to remove from SMS messages\n",
        "\n",
        "reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "\n",
        "df.replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df.replace('', np.nan, inplace=True)\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "K21QoP9agzJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with non-ASCII characters from the dataframe\n",
        "\n",
        "df = df[df['v2'].map(lambda x: x.isascii())]"
      ],
      "metadata": {
        "id": "VzHfLUaag2aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-English rows from the dataframe\n",
        "\n",
        "for i in range(len(df)):\n",
        "    try:\n",
        "        ['v2'][i] = detect.detect(df['v2'][i])\n",
        "        if df['v2'][i] != 'en':\n",
        "            df.drop(i, inplace=True, index=False)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "YZAKEBqDg6YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all the text data into lowercase\n",
        "\n",
        "df['v2'] = df['v2'].astype(str).str.lower()"
      ],
      "metadata": {
        "id": "B-fhDR47g-Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a list of English stop words and assign it to a var\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "U7u12CJ7hBSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the SMS messages in the dataframe\n",
        "\n",
        "df['TokenSMS'] = df.apply(lambda column: nltk.word_tokenize(column['v2']), axis=1)"
      ],
      "metadata": {
        "id": "_r0BUwqnhE32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TokenSMS'].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I0Q1NaohIqv",
        "outputId": "ffe05533-5968-420f-ad07-d0120d82dfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [go, until, jurong, point, crazy, available, o...\n",
              "1                       [ok, lar, joking, wif, u, oni]\n",
              "Name: TokenSMS, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column containing the Tokenized words without the stopwords\n",
        "\n",
        "df['StopTokenSMS'] = df['TokenSMS'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "metadata": {
        "id": "dIn3jwylhLXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a coolumn containting the StopTokenSMS text with words less than 2 characters\n",
        "\n",
        "df['LengthTokenSMS'] = df['StopTokenSMS'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))"
      ],
      "metadata": {
        "id": "TGAPeWJphOzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and the assigne a variable to the WordNetLemmatizer class\n",
        "\n",
        "wordnet_lem = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "_-fIhc8xhSVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column which contains the lemmatized words\n",
        "\n",
        "df['LemTokenSMS'] = df['LengthTokenSMS'].apply(wordnet_lem.lemmatize)"
      ],
      "metadata": {
        "id": "KjaDHwsChV62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean all dataframes again\n",
        "\n",
        "reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "\n",
        "df.replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "\n",
        "df.replace('', np.nan, inplace=True)\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "eOO14iq9hZRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CountVectorizer object\n",
        "\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# fit_transform the data to a numpy array\n",
        "\n",
        "x = cv.fit_transform(df['LemTokenSMS']).toarray()"
      ],
      "metadata": {
        "id": "GxUlPF47hdBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RReSeDJbhieR",
        "outputId": "1ddc9986-63c6-4c45-8f6c-8fb1bc0973a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4672, 6869)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'spam' with 1 and 'ham' with 0\n",
        "df['v1'] = df['v1'].replace({'spam': 1, 'ham': 0})"
      ],
      "metadata": {
        "id": "iaMS85f5hl48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the labels in  y\n",
        "\n",
        "y = df['v1'].values\n",
        "\n",
        "y.shape\n",
        "\n",
        "# convert y to to int type\n",
        "\n",
        "y = y.astype('int')"
      ],
      "metadata": {
        "id": "Q06hPjtKhopY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and testing set\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "KKxFl44ih3qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a MultinomialNB objec\n",
        "\n",
        "mnb=MultinomialNB()\n",
        "\n",
        "# Training the classifier and making predictions on the test data\n",
        "\n",
        "mnb.fit(x_train,y_train)\n",
        "y_pred=mnb.predict(x_test)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9o68ZjTh9gN",
        "outputId": "73e32029-e952-4136-ebaa-783c692cdd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9689839572192513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model to a file\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(mnb, file)\n",
        "\n",
        "# Save the model to a file\n",
        "with open('cv.pkl', 'wb') as file:\n",
        "    pickle.dump(cv, file)"
      ],
      "metadata": {
        "id": "yp2hlmw_iCT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model.pkl')\n",
        "files.download('cv.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TqlxzYUFiHb0",
        "outputId": "fc7ff828-9b88-433d-f00c-cae43a61ec5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a7430ad-3a00-413c-8a35-7322fed558e1\", \"model.pkl\", 220430)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be12883c-75af-42cd-8587-d12d057a6ad0\", \"cv.pkl\", 83819)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_log_prob = mnb.feature_log_prob_\n",
        "class_log_prior = mnb.class_log_prior_"
      ],
      "metadata": {
        "id": "6u_pgvUnt_fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = feature_log_prob.T\n",
        "intercepts = class_log_prior"
      ],
      "metadata": {
        "id": "tb9v_tdMuAgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = x_train.shape[1]  # Dimension of input features\n",
        "output_dim = len(set(y_train))"
      ],
      "metadata": {
        "id": "Arla-vKPtuKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(input_dim,)),\n",
        "    tf.keras.layers.Dense(output_dim, use_bias=True, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "0RQjcgQitvdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].set_weights([weights, intercepts])"
      ],
      "metadata": {
        "id": "va8jGFu0tyMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the TensorFlow model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lRqaCHjxuK2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, 'tf_model')"
      ],
      "metadata": {
        "id": "kcdOGPjwuNpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the TensorFlow model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('tf_model')\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "lsmByu9KuQGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.tflite', 'wb') as file:\n",
        "    file.write(tflite_model)"
      ],
      "metadata": {
        "id": "W1fy0QZ9uSpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a preprocessing function to process new text\n",
        "\n",
        "def clean_dataframe(df):\n",
        "    reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "    df['text'].replace(reg_vars, ' ', regex=True, inplace=True)\n",
        "    df['text'] = df['text'].astype(str).str.lower()\n",
        "    df['text'] = df.apply(lambda column: nltk.word_tokenize(column['text']), axis=1)\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stopwords])\n",
        "    df['text'] = df['text'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
        "    df['text'] = df['text'].apply(wordnet_lem.lemmatize)\n"
      ],
      "metadata": {
        "id": "dG6R64AEiKg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [{\"text\": \"Urgent dont miss news dun say so early hor... U c already then say lucky man\"}]\n",
        "\n",
        "ndf = pd.DataFrame(data)\n",
        "\n",
        "clean_dataframe(ndf)"
      ],
      "metadata": {
        "id": "9D8IMzIViT4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newtext = cv.transform(ndf['text']).toarray()\n",
        "prediction = mnb.predict(newtext)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5PbbTv8iWsC",
        "outputId": "a9d25100-a417-4d70-96c5-bf48211288a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Define regex patterns for cleaning\n",
        "    reg_vars = ['http\\S+', 'www\\S+', 'https\\S+', '\\W\\s+', '\\d+', '\\t+', '\\d+', '\\-+', '\\\\+', '\\/+', '\\\"+', '\\#+', '\\++', '\\@+', '\\$+', '\\%+', '\\^+', '\\&+', '\\*+', '\\(+', '\\)+', '\\[+', '\\]+', '\\{+', '\\}+', '\\|+', '\\;+', '\\:+', '\\<+', '\\>+', '\\?+', '\\,+', '\\.+', '\\=+', '\\_+', '\\~+', '\\`+', '\\s+']\n",
        "    # Remove regex patterns\n",
        "    for pattern in reg_vars:\n",
        "        text = re.sub(pattern, ' ', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stopwords]\n",
        "    # Lemmatize words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back into text\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Load the TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path='model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Preprocess new text data\n",
        "data = [{\"text\": \"Urgent dont miss news dun say so early hor... U c already then say lucky man\"}]\n",
        "ndf = pd.DataFrame(data)\n",
        "ndf['text'] = ndf['text'].apply(clean_text)\n",
        "\n",
        "# Convert text to TF-IDF vectors\n",
        "new_text_features = cv.transform(ndf['text']).toarray()\n",
        "\n",
        "# Perform inference\n",
        "predictions = []\n",
        "for x in new_text_features:\n",
        "    # Convert input data to FLOAT32\n",
        "    x = x.astype(np.float32)\n",
        "\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(x, axis=0))\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Assuming output is the predicted class probabilities\n",
        "    predictions.append(output)\n",
        "\n",
        "# Post-processing if necessary, such as converting probabilities to class labels\n",
        "\n",
        "# Example of printing predictions\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Sample {i+1} prediction: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4JfKlb1vF--",
        "outputId": "03897a3f-cb73-47d1-8b7f-67a38de58657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 prediction: [[1.000000e+00 9.913665e-09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted output class\n",
        "predicted_class = np.argmax(predictions[0])  # Assuming there's only one prediction\n",
        "print(\"Predicted class:\", predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36Rsv2-7v7cV",
        "outputId": "d6ab8e7e-4554-47a3-9796-acf6417e65db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0\n"
          ]
        }
      ]
    }
  ]
}